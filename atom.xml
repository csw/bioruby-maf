<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[BioRuby MAF blog]]></title>
  <link href="http://csw.github.com/bioruby-maf/atom.xml" rel="self"/>
  <link href="http://csw.github.com/bioruby-maf/"/>
  <updated>2012-08-05T18:40:18-04:00</updated>
  <id>http://csw.github.com/bioruby-maf/</id>
  <author>
    <name><![CDATA[Clayton Wheeler]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Bio-MAF 0.3.0]]></title>
    <link href="http://csw.github.com/bioruby-maf/blog/2012/07/18/bio-maf_0.3.0/"/>
    <updated>2012-07-18T12:48:00-04:00</updated>
    <id>http://csw.github.com/bioruby-maf/blog/2012/07/18/bio-maf_0.3.0</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/csw/bioruby-maf">bio-maf</a> version 0.3.0 is released. This version adds features
including <a href="https://github.com/csw/bioruby-maf#join-blocks-after-filtering-together">joining</a> adjacent MAF blocks when sequences that caused
them to be split have been filtered out; <a href="https://github.com/csw/bioruby-maf#extract-bio-alignment-representations-of-blocks">returning</a>
<a href="https://github.com/pjotrp/bioruby-alignment">bio-alignment</a> objects; and <a href="https://github.com/csw/bioruby-maf#extract-alignment-blocks-truncated-to-a-given-interval">truncating</a> (or &#8216;slicing&#8217;) alignment
blocks to only cover a given genomic interval.</p>

<p>For developers, this also adds a higher-level <a href="http://rdoc.info/github/csw/bioruby-maf/master/Bio/MAF/Access">Bio::MAF::Access</a> API
for working with directories containing indexed MAF files (or,
alternatively, single files), providing all relevant functionality for
indexed access in a simpler way than using the KyotoIndex and Parser
classes directly. The <a href="http://csw.github.com/bioruby-maf/man/maf_tile.1.html">maf_tile(1)</a> utility has been updated to use
this functionality; a directory of indexed MAF files can now be
specified, and the correct file will now be parsed as appropriate.</p>

<p>Usage of Enumerators and blocks has also been substantially improved;
all access methods for multiple blocks such as <code>Access#find</code>,
<code>Access#slice</code>, <code>Parser#each_block</code> now accept a block parameter,
which will be called for each block in turn. If no block parameter is
given, they will all return an <a href="http://www.ruby-doc.org/core-1.9.3/Enumerator.html">Enumerator</a> for the resulting
blocks. This is how most of the Ruby standard library,
e.g. <code>Array#each</code>, works.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bio-MAF 0.2.0]]></title>
    <link href="http://csw.github.com/bioruby-maf/blog/2012/07/09/bio-maf_0.2.0/"/>
    <updated>2012-07-09T22:59:00-04:00</updated>
    <id>http://csw.github.com/bioruby-maf/blog/2012/07/09/bio-maf_0.2.0</id>
    <content type="html"><![CDATA[<p>I have released <a href="https://github.com/csw/bioruby-maf">bio-maf</a> version 0.2.0 as a Ruby gem. The main new
feature in this release is MAF &#8216;tiling&#8217;; combining the alignment
blocks covering a given genomic interval, optionally filling in gaps
with reference sequence data, to output a single alignment block. See
the <a href="https://github.com/csw/bioruby-maf#tile-blocks-together-over-an-interval">README</a> for more details. This includes a <a href="http://csw.github.com/bioruby-maf/man/maf_tile.1.html">maf_tile(1)</a>
tool. The name of this feature, and inspiration for the
implementation, comes from the <a href="https://bitbucket.org/james_taylor/bx-python/wiki/Home">bx-python</a> implementation.</p>

<p>This release also enables <a href="https://github.com/csw/bioruby-maf#remove-gaps-from-parsed-blocks">gap removal</a> in cases where removal of
some species from an alignment block leaves a gap in all remaining sequences.</p>

<p>Other fixes and improvements include:</p>

<ul>
<li><a href="https://github.com/csw/bioruby-maf/issues/59">#59</a>: returning
blocks in sorted order</li>
<li><a href="https://github.com/csw/bioruby-maf/issues/56">#56</a>: avoiding a
race condition in parallel parsing</li>
<li>Using all available cores by default under JRuby</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kyoto Cabinet support for JRuby]]></title>
    <link href="http://csw.github.com/bioruby-maf/blog/2012/07/02/kyoto_cabinet_support_for_jruby/"/>
    <updated>2012-07-02T16:01:00-04:00</updated>
    <id>http://csw.github.com/bioruby-maf/blog/2012/07/02/kyoto_cabinet_support_for_jruby</id>
    <content type="html"><![CDATA[<p><a href="http://fallabs.com/kyotocabinet/">Kyoto Cabinet</a> is a useful database, with a convenient
<a href="http://fallabs.com/kyotocabinet/rubydoc/">Ruby binding</a>; unfortunately, this uses Ruby&#8217;s C extension API and
so does not work with JRuby. Since JRuby has a considerable
performance advantage over MRI for my <a href="https://github.com/csw/bioruby-maf">MAF parser</a>, I needed a way
of using Kyoto Cabinet from JRuby. I have released the
<a href="https://github.com/csw/kyotocabinet-java">kyotocabinet-java</a> gem to provide this. It is not complete, but it
wraps enough of the API for my needs, and the rest should be simple to
cover.</p>

<p>This gem contains a patched copy of the Kyoto Cabinet
<a href="http://fallabs.com/kyotocabinet/javapkg/">Java library</a>, along with a thin Ruby adaptation layer to provide
the usual Ruby API. Since the underlying Java library relies on native
code integrated with JNI, installing the gem compiles the native
library and associated Java code, and thus requires a JDK and working
C++ compiler as well as a Kyoto Cabinet installation.</p>

<p>Mapping the Java API onto the Ruby API is generally quite simple.  The
chief issue is ensuring that Ruby strings are converted to Java byte
arrays rather then Java strings; the Java string versions of the API
methods fail completely with binary data. Also, the Java API lacks the
Ruby API&#8217;s optional parameters. For instance, here is <a href="https://github.com/csw/kyotocabinet-java/blob/c51e23a4fee077229b0ffdf4b66d323b33635704/lib/kyotocabinet.rb#L105">DB#get</a>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">alias_method</span> <span class="ss">:_get</span><span class="p">,</span> <span class="ss">:get</span>
</span><span class='line'><span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
</span><span class='line'>  <span class="n">ret_bytes</span><span class="p">(</span><span class="nb">self</span><span class="o">.</span><span class="n">_get</span><span class="p">(</span><span class="n">key</span><span class="o">.</span><span class="n">to_java_bytes</span><span class="p">))</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>A few methods needed a tiny bit more work, such as <code>DB#set_bulk</code> and
<code>DB#cursor_process</code>, but as you can see from <a href="https://github.com/csw/kyotocabinet-java/blob/master/lib/kyotocabinet.rb">kyotocabinet.rb</a>, it
wasn&#8217;t much.</p>

<p>Using this and the <code>kyotocabinet-ruby</code> library interchangeably for MRI
and JRuby support in a Bundler application is straightforward:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="n">gem</span> <span class="s2">&quot;kyotocabinet-ruby&quot;</span><span class="p">,</span> <span class="s2">&quot;~&gt; 1.27.1&quot;</span><span class="p">,</span> <span class="ss">:platforms</span> <span class="o">=&gt;</span> <span class="o">[</span><span class="ss">:mri</span><span class="p">,</span> <span class="ss">:rbx</span><span class="o">]</span>
</span><span class='line'><span class="n">gem</span> <span class="s2">&quot;kyotocabinet-java&quot;</span><span class="p">,</span> <span class="s2">&quot;~&gt; 0.2.0&quot;</span><span class="p">,</span> <span class="ss">:platforms</span> <span class="o">=&gt;</span> <span class="ss">:jruby</span>
</span></code></pre></td></tr></table></div></figure>


<p>Unfortunately, if you are developing a gem as I am with
<a href="https://github.com/csw/bioruby-maf">bioruby-maf</a>, things are not quite so simple. While Bundler makes
it easy to require different gems depending on one&#8217;s current Ruby
platform, <a href="http://docs.rubygems.org/read/chapter/20">Gem::Specification</a> provides no such feature. I ended up
making a <a href="https://github.com/csw/bioruby-maf/blob/eda7485e61aba4978ba16a6abcdc95b8094a722d/bio-maf.gemspec#L102">gemspec</a> that builds two different versions of the gem: a
<code>java</code> platform variant that depends on <code>kyotocabinet-java</code>, and a
&#8216;normal&#8217; gem with no platform specified that depends on
<code>kyotocabinet-ruby</code>. This is a bit cumbersome; it requires running
<code>gem build</code> under both JRuby and MRI to build both versions of the
gem, and meant that I had to abandon use of Jeweler. Nonetheless, it
works; under JRuby, <code>gem install bio-maf</code> will pull in the Java
variant and <code>kyotocabinet-java</code>, while under MRI it will pull in the
&#8216;normal&#8217; gem and <code>kyotocabinet-ruby</code>. The relevant part of the gemspec
is:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="k">if</span> <span class="no">RUBY_PLATFORM</span> <span class="o">==</span> <span class="s1">&#39;java&#39;</span>
</span><span class='line'>  <span class="n">s</span><span class="o">.</span><span class="n">platform</span> <span class="o">=</span> <span class="s1">&#39;java&#39;</span>
</span><span class='line'><span class="k">end</span>
</span><span class='line'><span class="o">[.</span><span class="n">.</span><span class="o">.]</span>
</span><span class='line'><span class="k">if</span> <span class="no">RUBY_PLATFORM</span> <span class="o">==</span> <span class="s1">&#39;java&#39;</span>
</span><span class='line'>  <span class="n">s</span><span class="o">.</span><span class="n">add_runtime_dependency</span><span class="p">(</span><span class="s1">&#39;kyotocabinet-java&#39;</span><span class="p">,</span> <span class="o">[</span><span class="s2">&quot;~&gt; 0.2.0&quot;</span><span class="o">]</span><span class="p">)</span>
</span><span class='line'><span class="k">else</span>
</span><span class='line'>  <span class="n">s</span><span class="o">.</span><span class="n">add_runtime_dependency</span><span class="p">(</span><span class="s1">&#39;kyotocabinet-ruby&#39;</span><span class="p">,</span> <span class="o">[</span><span class="s2">&quot;~&gt; 1.27.1&quot;</span><span class="o">]</span><span class="p">)</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>Ultimately, it might be worth contacting the maintainer of the
<code>kyotocabinet-ruby</code> gem and seeing about packaging this as a platform
variant, to sidestep all this. For the time being, though, this works.</p>

<p>A note on performance: I found JRuby&#8217;s ObjectProxyCache to be a major
performance bottleneck, especially for multithreaded access to Kyoto
Cabinet. Starting JRuby with the <code>-Xji.objectProxyCache=false</code> option
gave about a 2.5x speedup for Kyoto Cabinet searches. If the rest of
your JRuby code works with this option (which will be the default in
JRuby 2.0, anyway), I highly recommend using it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Parallel I/O]]></title>
    <link href="http://csw.github.com/bioruby-maf/blog/2012/06/21/parallel_io/"/>
    <updated>2012-06-21T00:47:00-04:00</updated>
    <id>http://csw.github.com/bioruby-maf/blog/2012/06/21/parallel_io</id>
    <content type="html"><![CDATA[<p>Some applications of a MAF parser call for sequential processing of an
entire MAF file, but in many cases random access is necessary. I found
that a single-threaded parsing approach worked tolerably well for
sequential access, with OS-level readahead helping, but that
single-threaded performance with random access was very poor
indeed. With a test scenario, I was only able to parse 10.5 MB/s from
a SATA hard disk, and 34.3 MB/s from a MacBook Air SSD.</p>

<p>My next step was to parallelize random I/O for index-based
queries. With Ruby 1.9.3, this was pointless, since its GIL prevents
any useful parallelism, but with JRuby there was ample scope for
improvement. In the end, I implemented several parallel I/O
subsystems: one with a pool of independent threads reading and parsing
groups of blocks, one with separate pools of reader and parser
threads, and one using an <a href="https://github.com/csw/bioruby-maf/blob/0b7210716be6ce3eb47c167db2fecf6f5539a240/lib/bio/maf/parallel_io.rb">adaptive parallel I/O subsystem</a> modeled
after Dmitry Vyukov&#8217;s <a href="http://www.1024cores.net/home/scalable-architecture/wide-finder-2">Wide Finder entry</a>.</p>

<p>As test data for this, I used chr22.maf from the <a href="http://hgdownload.cse.ucsc.edu/goldenPath/hg18/multiz28way/maf/">hg18</a> data set and
a set of 10,000 randomly generated genomic intervals from its
reference sequence, along with an index for the MAF file. I tested
performance with all three I/O subsystems on hard disk and SSD
storage, and of course with various numbers of threads, queue sizes,
and so forth.</p>

<p>To my surprise, I found that my first implementation, with independent
worker threads reading and immediately parsing MAF blocks,
outperformed the others. Quite possibly this is because the data being
parsed has just been read into cache by the same thread. It is
possible that the adaptive implementation could be competitive with
it, but it was challenging to tune it properly for this workload in a
way that worked with slow and fast storage alike. Further work on this
might be promising.</p>

<p>In the end, the first implementation delivered a maximum of 26 MB/s
from hard disk, and 136 MB/s from SSD; the implementation with
separate reader and parser threads seemed to top out at 24 and 104
MB/s respectively.</p>

<p>Almost as striking, however, was the difference between a single run
and the third or fourth run repeated back-to-back in the same JVM
instance. In some cases, performance almost doubled, from 87 to 136
MB/s in a representative case. File system caching was ruled out, but
intensive HotSpot compiler activity was observed, so I would attribute
this to the combined optimization activity of the JRuby and HotSpot
JIT compilers.</p>

<h2>Index scanning</h2>

<p>An unexpected bottleneck was observed: at peak performance,
single-threaded scanning of the 16 MB index to select the blocks to
parse takes 6.9 seconds, nearly as long as it took to parse the 869 MB
of MAF data. <a href="https://github.com/csw/bioruby-maf/commit/4deee8548bfbc2899baae0c1f81893f64a10b5eb">Optimizing the match test</a> used produced a significant
speedup, but past that, no optimization attempts have had much
success.</p>

<p>Parallelizing the index scan showed a modest improvement with two
threads, topping out around 5.2 seconds; more than two threads have
resulted in negligible improvements. Currently, the two-thread
parallel scan is the default under JRuby.</p>

<p>Starting the scan <a href="https://github.com/csw/bioruby-maf/commit/50bbc0fdcab6906a80f00cd42bd4928aaec20403">at the first block of interest</a> rather than at
the start of the bin added noticeable complexity for no detectable
performance gain. <a href="https://github.com/csw/bioruby-maf/commit/624447dd9d61f9b9b5acebfe669e10a7aae5596d">Running the index scan in parallel</a> with the
block parsing seemed like a reasonable approach, but turned out to be
slower than performing the two operations sequentially.</p>

<h2>JRuby and java.util.concurrent</h2>

<p>A significant benefit of using JRuby is having access to the
<a href="http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/package-summary.html">java.util.concurrent</a> library. Its blocking queues made parallel
parsing simple to implement, and parallel index scans were even easier
with the ExecutorCompletionService. Since JRuby objects are JVM
objects like any other, and JRuby threads are implemented atop JVM
threads, it was perfectly easy to use these.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JRuby support and I/O performance]]></title>
    <link href="http://csw.github.com/bioruby-maf/blog/2012/06/13/jruby_support_and_performance_work/"/>
    <updated>2012-06-13T22:54:00-04:00</updated>
    <id>http://csw.github.com/bioruby-maf/blog/2012/06/13/jruby_support_and_performance_work</id>
    <content type="html"><![CDATA[<h2>I/O performance and the Magic Number</h2>

<p>My MAF parser is designed to read data from disk in relatively large
chunks before parsing it, to minimize read(2) calls. I started out
using a chunk size of 8 MB, but using the <a href="">jvisualvm</a> profiler with
JRuby, I observed that during index builds with <code>maf_index</code>, it was
spending about 37% of its time in
<code>org.jruby.util.io.ChannelDescriptor.read()</code> calls. (I had observed
MRI spending a similar amount of time in read calls as well.) Since
Mac OS X has DTrace, I used <a href="http://www.brendangregg.com/DTrace/iosnoop">iosnoop</a> to watch the I/O activity at
the OS level, and observed that reads were actually being issued with
sizes of 128k:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  501 55424 R 1139635624 131072       java ??/maf/chr22.maf
</span><span class='line'>  501 55424 R 1139635880 131072       java ??/maf/chr22.maf
</span><span class='line'>  501 55424 R 1139636136 131072       java ??/maf/chr22.maf
</span><span class='line'>  501 55424 R 1139636392 131072       java ??/maf/chr22.maf
</span><span class='line'>  501 55424 R 1139636904 131072       java ??/maf/chr22.maf</span></code></pre></td></tr></table></div></figure>


<p>Suspecting that merging the data from these read calls into an 8 MB
buffer might be a problem, I changed the chunk size constant
(<code>SEQ_CHUNK_SIZE</code>) to 128k to match, and saw the processing rate jump
from 19 MB/s to 30 MB/s, with only 2.4% of CPU time spent in
<code>ChannelDescriptor.read()</code>.</p>

<p>MRI 1.9.3 exhibited a similar improvement, from 18 to 24 MB/s.</p>

<p>It turns out, though, that 128k is not, as I guessed, a hard-coded
Ruby setting. I later ran the same test on my MacBook Air&#8217;s built-in
SSD instead of a USB-attached SATA disk, and saw I/O sizes of 1048576
instead. Here, changing the chunk size to match showed no significant
improvement. Presumably this is due to the lower I/O latency of the
SSD.</p>

<p>Requiring users to divine the best I/O size for their environment to
achieve the best parsing performance seems a bit arcane; I wonder if
it might be worthwhile to try to automatically detect the
best-performing chunk size at runtime by defaulting to 128k, varying
it in both directions, and tracking average latencies.</p>

<h2>JRuby support with Kyoto Cabinet</h2>

<p>Kyoto Cabinet has turned out to perform well and be easy to
use. However, while the parser code runs substantially faster under
JRuby, there is not a straightforward out-of-the-box way to use Kyoto
Cabinet with Ruby. The standard <code>kyotocabinet-ruby</code> gem uses the C
Extension API, so it isn&#8217;t really practical to use with
JRuby. (Technically, JRuby has partial support for the C Extension
API, but at least on my machine, it&#8217;s broken in several ways under
RVM, needs to be enabled with a specific runtime option, and is
generally frowned upon.) However, Kyoto Cabinet also has a Java API;
both it and the Ruby API are based on the same underlying C++ library,
so the APIs are quite similar. I wrote a small Ruby <a href="https://github.com/csw/bioruby-maf/blob/8e90c5d5f58524052e5d19d9ea6956ec361bf85b/lib/kyotocabinet-java.rb">wrapper</a> around
the Java library, so it can be used under JRuby in an identical way to
the native Ruby library.</p>

<p>Unfortunately, this still requires users to build and install the
JNI-based [Java library][] for Kyoto Cabinet as well as Kyoto Cabinet
itself. This isn&#8217;t ideal, but shouldn&#8217;t be too difficult. I plan to
separate this out as its own gem.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Filtering work]]></title>
    <link href="http://csw.github.com/bioruby-maf/blog/2012/06/09/filtering-work/"/>
    <updated>2012-06-09T11:46:00-04:00</updated>
    <id>http://csw.github.com/bioruby-maf/blog/2012/06/09/filtering-work</id>
    <content type="html"><![CDATA[<p>I think I made good progress in the end this week, although it was a
bit frustrating along the way, with a few dead ends and some
challenges in figuring out the right approaches to things. My main
goal was to implement MAF file filtering on queries, as specified in a
<a href="https://github.com/csw/bioruby-maf/blob/86e9f0fb30723a0df19f948b1aa9c9bd36def8f8/features/maf-querying.feature">Cucumber feature</a> and <a href="https://github.com/csw/bioruby-maf/issues/22">Github issue</a>.</p>

<p>This is all working now, and I&#8217;ve managed to do all the alignment
block filtering using the index, to avoid having to parse blocks to
test whether they meet criteria for e.g. presence of species. I&#8217;m
storing things like the number of sequences, the text size, and a bit
vector of species present in the index, and checking those when
building the list of MAF blocks to read from disk. I think this is an
improvement over bx-python, which does this sort of thing by a
combination of post-parsing filtering and writing out modified MAF
files.</p>

<p>I tried using external libraries to provide somewhat nicer interfaces
to binary record access (<a href="http://rdoc.info/gems/bindata">bindata</a>) and bit vector manipulation
(<a href="http://bitstring.rubyforge.org/rdoc/">bitstring</a>); they are both nice and well-thought out libraries but
turned out to have awful performance, so I ended up ripping them both
out. (I got about a 120% performance boost when building indexes by
using raw Array#pack calls instead of bindata, and then about 100% by
using Integers and shifts instead of bitstring.)</p>

<p>I think in the future I will do microbenchmarks before integrating
things like these; I wouldn&#8217;t have expected such a high performance
penalty for such conceptually simple operations.</p>

<p>Ultimately, I wrote my own little <a href="https://github.com/csw/bioruby-maf/blob/master/spec/bio/maf/struct_spec.rb">library</a> for building format strings,
after making a few arithmetic mistakes when calculating byte offsets
in my head. I also wrote a <a href="https://github.com/csw/bioruby-maf/blob/7ebeeb03c7b3e9755978f4c4307312e13451b0e6/lib/bio/maf/index.rb#L177">bit of code</a> to dump out binary indexes in
human-readable form, to help with debugging.</p>

<p>The <a href="https://github.com/csw/bioruby-maf/blob/master/features/step_definitions/query_steps.rb">API</a> for this filtering code could perhaps use some work. I&#8217;ll
need to think about that further.</p>

<p>I also made some progress on getting Kyoto Cabinet and JRuby working
together, although it&#8217;s not quite there yet. Along the way, I
discovered what looks like an interesting <a href="https://github.com/csw/bioruby-maf/issues/31">JRuby bug</a>.</p>

<p>And I&#8217;ve got tests passing on Travis CI again, after adding a script
to build and install Kyoto Cabinet there.</p>

<p>After working through and thinking about things this week, and
particularly in light of Francesco&#8217;s comments, I have a few questions
I need to look into about MAF and MAF workflows:</p>

<ul>
<li>Is it possible for alignment blocks to overlap, at least with
respect to the reference sequence?</li>
<li>Is it useful to build indexes on other sequences besides the
reference sequence?</li>
<li>What is the longest (in terms of text size, i.e. sequence data
including dashes) alignment block I should be prepared to encounter?
(That is, does its length need to be 32 bits? 16? 64?)</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Indexed MAF access]]></title>
    <link href="http://csw.github.com/bioruby-maf/blog/2012/06/04/indexed_maf_access/"/>
    <updated>2012-06-04T16:33:00-04:00</updated>
    <id>http://csw.github.com/bioruby-maf/blog/2012/06/04/indexed_maf_access</id>
    <content type="html"><![CDATA[<p>My second week of working on this MAF library was more of a struggle
than the first week. I was implementing indexing of MAF files and
using those indexes to enable searching by genomic regions. In the
process of doing this, I ended up changing directions partway through,
but I eventually did implement the features I had planned to, and
ended up with a better implementation than I thought I would.</p>

<p>MAF files can be quite large, often hundreds of gigabytes. Frequently,
too, a user will want to extract a relatively small subset of that
data. Reading in and parsing an entire 200 GB file to find a few
alignments of interest is not a very useful approach; instead, we want
to build indexes to enable quick location of the alignments to parse.</p>

<p>This was, in fact, my <a href="https://github.com/csw/bioruby-maf/issues?milestone=2&amp;state=closed">milestone</a> for this week: to be able to build
an index for a MAF file, identify alignment blocks matching a region
of interest, and then selectively parse those blocks from the MAF
file. The two MAF implementations I&#8217;m aware of that use a similar
indexing scheme are <a href="https://github.com/polyatail/biopython/tree/alignio-maf">Biopython</a> and <a href="https://bitbucket.org/james_taylor/bx-python/wiki/Home">bx-python</a>; Biopython uses the
SQLite embedded relational database to build its indexes, and
bx-python uses a custom <a href="https://bitbucket.org/james_taylor/bx-python/src/07aca5a9f6fc/lib/bx/interval_index_file.py">index file format</a>. (I believe the UCSC
genome browser uses MySQL for indexing in general, but I&#8217;m not sure
whether this is applied to MAF files directly.)</p>

<h3>SQLite vs. Kyoto Cabinet</h3>

<p>The plan I started with was to use SQLite for indexing in a similar
way to Biopython, in order to bring up functional code with indexing
support as quickly as possible. I reasoned that being able to use SQL
for declarative queries would make this simpler than, say, using a
key-value store such as <a href="http://fallabs.com/kyotocabinet/">Kyoto Cabinet</a> or <a href="http://en.wikipedia.org/wiki/Berkeley_DB">Berkeley DB</a>, let
alone implementing a <em>sui generis</em> indexing system such as the one
bx-python uses.</p>

<p>My first task, though, was to understand the UCSC
<a href="http://genomewiki.ucsc.edu/index.php/Bin_indexing_system">bin indexing system</a>, which is used by all MAF indexing
implementations. It was not particularly clear to me how it worked,
even after looking at several implementations of it, until I finally
read the <a href="http://genome.cshlp.org/content/12/6/996.full">paper</a> describing it and illustrating its hierarchical
nature. I still don&#8217;t understand why Biopython <a href="https://github.com/polyatail/biopython/blob/alignio-maf/Bio/AlignIO/MafIO.py#L318">always searches</a> bin
1, which was puzzling me for a while; I need to ask the author.</p>

<p>I ran into a series of problems with using SQLite,
unfortunately. First, the standard <code>sqlite3</code> gem uses the C extension
API rather than FFI, and so does not work with JRuby. To use the same
code with the native and JDBC drivers, I needed to use the
unmaintained DBI/DBD library. (I subsequently learned that <a href="http://sequel.rubyforge.org/">Sequel</a>
might have worked as well, but after I&#8217;d already decided to try
another tack.) The DBI interface also had the unfortunate feature of
returning all numeric values as strings, which was not what I would
hope for in performance-critical code.</p>

<p>Also, I discovered that SQLite does not have clustered indexes,
meaning that I needed to create a table just to hold the index data,
and then a separate index within SQLite for that data. This duplicates
the index data, which is also not ideal.</p>

<p>Most of all, though, SQL simply turned out to be too
cumbersome. Explicitly creating and indexing tables and checking for
their existence started consuming more of my effort than I would have
liked. Biopython&#8217;s <a href="https://github.com/polyatail/biopython/blob/alignio-maf/Bio/AlignIO/MafIO.py#L384">implementation</a> ended up running a SQL query for
each possible bin for each range of interest; I knew that it should be
possible to execute a search like this while only having to make a
single pass through the index data for each bin. It wasn&#8217;t clear that
there was a good (and simple) way to do this in SQL, though.</p>

<p>In frustration, I opened up the Kyoto Cabinet documentation, studied
the available features for prefix and range searches, and wrote out
the <a href="https://github.com/csw/bioruby-maf/blob/4b0fb7b97c6185d912515dbf1903c0f066d2b901/lib/bio/maf/index.rb#L122">algorithm</a> I had in mind. My biggest decision point was how
exactly to store the index data. In the past, I&#8217;ve always favored
human-readable data representations; I&#8217;ve generally dealt with small
amounts of data in situations where being able to see the data
immediately with View Source or a packet trace is invaluable. Here,
though, after adding things up I realized I could use a binary
representation and use a mere 24 bytes per index record. This actually
may be the first time I&#8217;ve written something to output a binary data
representation, but I think it was well worth it.</p>

<p>Once I sat down to actually implement the Kyoto Cabinet version, I was
amazed how much simpler it was than the SQLite version. I could step
through the data just the way I wanted to, and do whatever computation
seemed appropriate on the way. I pulled together a running version
very quickly, and simply applied the same RSpec tests to both.</p>

<p>For both implementations of this indexing code, I found RSpec
invaluable. I made a fairly rigorous effort to implement this in
BDD/TDD style, writing <a href="https://github.com/csw/bioruby-maf/blob/4b0fb7b97c6185d912515dbf1903c0f066d2b901/spec/bio/maf/index_spec.rb">tests</a> for each bit of behavior I could
think of to specify. This gave me a great deal of confidence in
optimizing and tweaking the index search code.</p>

<h3>Kyoto Cabinet results</h3>

<p>I&#8217;m now very happy with the Kyoto Cabinet code; I also expect it to be
easily adapted to other key-value stores such as leveldb or Berkeley
DB.</p>

<p>Getting Kyoto Cabinet working on JRuby has posed a bit of a headache
too, unfortunately. Its Ruby library also uses the C extension API, so
I plan to use the Kyoto Cabinet Java library instead, with a thin
adaptation layer to present a compatible interface to the Ruby
library. This approach has been promising, except that a few of the
methods in the Java library seem to encounter string encoding problems
with binary data, returning garbage strings (probably containing
Unicode &#8216;REPLACEMENT CHARACTER&#8217;, I need to check) rather than the
expected data. Many of the Java methods have separate String and
byte[] versions, but not all. Ironically, the trickiest problems of
this kind are caused by <code>DB#match_prefix</code> calls in my unit tests,
rather than in the actual indexing code.</p>

<p>Another oddity has been that there don&#8217;t appear to be any Ubuntu
packages in usable form for Kyoto Cabinet. This is strange, since it&#8217;s
hardly the most obscure software I&#8217;ve wanted packages for. I don&#8217;t
need these for development, but <a href="http://travis-ci.org/">Travis CI</a> doesn&#8217;t provide Kyoto
Cabinet, so I have to install it myself there to get CI working
again. Since I&#8217;m not about to teach myself Debian packaging just for
this, I&#8217;ve written a <a href="https://github.com/csw/bioruby-maf/blob/0c2eabdd5f2e2efe2c3fd3e9559e84bed6dd1dec/travis-ci/install_kc">horrible shell script</a> instead for the time
being. (What would really be nice is an easy way to run user-provided
Chef recipes on Travis CI, but they don&#8217;t appear to provide one.)</p>

<h3>Random-access parsing</h3>

<p>The trickiest part of the whole effort may have been figuring out how
to revise the parsing code to work in a truly random-access fashion,
and in a way that will be compatible with <a href="http://blastedbio.blogspot.com/2011/11/bgzf-blocked-bigger-better-gzip.html">BGZF</a> compression later
on. What I ended up doing was extracting a separate <a href="https://github.com/csw/bioruby-maf/blob/4b0fb7b97c6185d912515dbf1903c0f066d2b901/lib/bio/maf/parser.rb#L57">ChunkReader</a>
class responsible for positioning within the file and reading
appropriately-sized chunks of it as requested while maintaining proper
chunk alignment. Together with other code to <a href="https://github.com/csw/bioruby-maf/blob/4b0fb7b97c6185d912515dbf1903c0f066d2b901/lib/bio/maf/parser.rb#L138">merge requests</a> for
adjoining or nearby alignment blocks, this keeps the basic parsing
logic intact but should avoid either excessive or excessively large
reads.</p>

<p>This also means that the indexing code simply provides the starting
offset of each block, and the parser is responsible for reading ahead
as appropriate. This should be perfectly compatible with a BGZF layer,
even if an alignment block spans the boundary between separate BGZF
blocks. (Alignment blocks, chunks, and now BGZF blocks&#8230; I may be
heading for a terminology problem here.)</p>

<h3>Next steps</h3>

<p>This week, I&#8217;m focusing on providing additional logic for filtering
and querying for sequences and alignment blocks. I&#8217;m also working on a
few ideas to optimize index creation, and I hope to get my index code
running on JRuby soon.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First milestone]]></title>
    <link href="http://csw.github.com/bioruby-maf/blog/2012/05/25/first_milestone/"/>
    <updated>2012-05-25T14:13:00-04:00</updated>
    <id>http://csw.github.com/bioruby-maf/blog/2012/05/25/first_milestone</id>
    <content type="html"><![CDATA[<p>It&#8217;s the end of my first week of actual development work, and I&#8217;m
happy with my progress. My <a href="https://github.com/csw/bioruby-maf/issues?milestone=1&amp;state=closed">first milestone</a>, for batch MAF
conversion to <a href="http://en.wikipedia.org/wiki/FASTA_format">FASTA</a>, is complete. I started with a simple
line-based parser, and then spent some time developing a faster one;
my MAF parser now appears to be quite competitive in performance. I
can now convert simple MAF files to FASTA with output matching that
from the <a href="http://galaxy.psu.edu/">Galaxy</a> tools. And I&#8217;m fairly confident in its
correctness, with RSpec <a href="https://github.com/csw/bioruby-maf/blob/master/spec/bio/maf/parser_spec.rb">unit tests</a> and Cucumber <a href="https://github.com/csw/bioruby-maf/blob/master/features/maf-parsing.feature">features</a>
specifying its behavior relatively completely.</p>

<h2>Parser development</h2>

<p>My initial approach was to simply process the file line-by-line,
calling <a href="http://www.ruby-doc.org/core-1.9.3/IO.html#method-i-readline">IO#readline</a> each time. This turned out to be a little more
cumbersome than I expected. Also, there was a <a href="http://lists.open-bio.org/pipermail/biopython-dev/2012-April/009561.html">discussion</a> on the
Biopython list of the usefulness of <a href="http://blastedbio.blogspot.com/2011/11/bgzf-blocked-bigger-better-gzip.html">BGZF</a> blocked compression for
MAF files, which would not fit well with such a linear line-oriented
approach. Inspired by Dmitry Vyukov&#8217;s <a href="http://www.1024cores.net/home/scalable-architecture/wide-finder-2">Wide Finder 2 entry</a>, I wrote
a <a href="https://github.com/csw/bioruby-maf/blob/d424245c047e3939d1e42b97c002c02fc8b578ac/lib/bio/maf/parser.rb#L61">new parser</a> which reads the file in 8 MB chunks. It immediately
locates the start of the last MAF alignment block in that chunk, and
then proceeds to scan through the chunk, parsing an alignment block at
a time, until the last block is reached. When it reaches the last
block, it <a href="https://github.com/csw/bioruby-maf/blob/d424245c047e3939d1e42b97c002c02fc8b578ac/lib/bio/maf/parser.rb#L130">joins the block fragments</a> at the end of one
chunk and the beginning of the next chunk.</p>

<p>For separating the alignment blocks within each chunk, using a
StringScanner and regexes worked well, but for parsing the individual
alignment blocks, using String#split to split the block into lines,
dispatching on the first character with a case statement and plain
string comparisons, and splitting lines into fields turned out to
perform substantially better. I suspect the overhead of setting up a
regex matching operation is the reason for this; profiling indicated
that it was spending considerable time in regex operations, at any rate.</p>

<p>After this optimization, the chunked parser was able to parse a 315
MB file and count its MAF blocks in 10.1 s, compared to 16.0 s for the
earlier line-based parser and 22.7 s for the parser from Galaxy&#8217;s
bx-python library. This seems like very respectable performance.</p>

<p>Also, the upcoming JRuby 1.7 on Java 7 appears to have excellent
performance with the chunked parser, perhaps due to the new
<a href="http://blog.headius.com/2011/08/jruby-and-java-7-what-to-expect.html">invokedynamic support</a>. After warming up the JVM, it averaged 16
&mu;s per alignment block parsed, compared to 25 &mu;s for Ruby
1.9.3. See the <a href="https://github.com/csw/bioruby-maf/wiki/Performance">performance page</a> on the project wiki for details.</p>

<h2>Behavior-Driven Development</h2>

<p>At the beginning of this week, I was not at all clear on when it would
make sense to use Cucumber and when to use RSpec. After writing a
<a href="https://github.com/csw/bioruby-maf/blob/d77ef2e133edf449a4ac3b18ff7d21052c0fc14a/features/maf-parsing.feature">Cucumber feature</a> to ensure that sequence data was exposed
properly, it didn&#8217;t seem worthwhile to duplicate that in
RSpec. However, the chunked parser was much harder to get right than
the original line-based parser, and RSpec was an invaluable tool for
that.</p>

<p>For most of the bugs I found, I developed an RSpec specification to
call for the correct behavior. Some of these could go into Cucumber
just as well, such as the one stipulating that a certain alignment
block should have ten sequences in it. Most, though, are about
low-level details such as correct parsing of
<a href="https://github.com/csw/bioruby-maf/blob/b3b9e060c6ba40bf17930eb6564615eb3b5b31bf/spec/bio/maf/parser_spec.rb#L138">sequence lines split across chunk boundaries</a>.</p>

<p>In some cases it was challenging to follow the BDD principle of
writing only the necessary code to make the next test pass. When I
started on the chunked parser, I had a very clear idea of how it
needed to work, and next to no idea how to specify that in terms of
tests. So I just started writing code and relying on the existing
parser tests. However, the set of RSpec tests I ended up with seems to
specify the chunked parser&#8217;s behavior reasonably well; they specify
where the last block in a chunk should be detected, how many blocks
should be parsed in a file if chunk fragments are being joined
properly, what happens if a sequence line is split across a chunk
boundary, and so on.</p>

<p>This gives me a concrete idea of the kind of tests I might want to
write to specify something like this next time. We&#8217;ll see how well I
can apply this next week, when I start working on indexed access.</p>

<h2>Tools</h2>

<p>I knew that it was possible to set up <a href="http://travis-ci.org/#!/csw/bioruby-maf">continuous integration</a> as a
hosted service with <a href="http://travis-ci.org/">Travis-CI</a>, but it was a pleasant surprise to
find that I could also have <a href="http://rubydoc.info/github/csw/bioruby-maf/">documentation</a> generated the same
way. It would be nice to have Travis-CI do hosted coverage reporting
as well, but setting up <a href="https://github.com/colszowka/simplecov">simplecov</a> was very easy.</p>

<p>I&#8217;ve been doing my development work with Emacs and using
<a href="http://barelyenough.org/projects/rspec-mode/">rspec-mode</a>, <a href="https://github.com/michaelklishin/cucumber.el">cucumber.el</a>, and <a href="https://github.com/magit/magit">Magit</a>. These have all been
better than nothing, but also somewhat frustrating; I&#8217;ve already sent
in one <a href="https://github.com/michaelklishin/cucumber.el/pull/21">pull request</a> for cucumber.el, and over the next
month or two I may explore some more radical ideas to make rspec-mode
and cucumber.el more useful. I&#8217;ve been gradually learning how to use
Magit, although I usually end up doing my more complex Git operations
from the command line.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Basic MAF parsing]]></title>
    <link href="http://csw.github.com/bioruby-maf/blog/2012/05/21/basic-maf-parsing/"/>
    <updated>2012-05-21T13:43:00-04:00</updated>
    <id>http://csw.github.com/bioruby-maf/blog/2012/05/21/basic-maf-parsing</id>
    <content type="html"><![CDATA[<p>Today is the official start of coding for GSoC. Following my
<a href="https://github.com/csw/bioruby-maf/wiki/Original-proposal">initial plan</a>,
I&#8217;m going to begin by implementing the basics of MAF parsing in
Ruby. I&#8217;ve already got Cucumber features defined for
<a href="https://github.com/csw/bioruby-maf/blob/master/features/maf-parsing.feature">basic MAF parsing</a>
and
<a href="https://github.com/csw/bioruby-maf/blob/master/features/maf-to-fasta.feature">conversion to FASTA</a>,
along with
<a href="https://github.com/csw/bioruby-maf/tree/master/test/data">reference data</a>
as processed by bx-python.</p>

<p>This should be fairly straightforward to implement, but I&#8217;m going to
wait until I&#8217;ve got this basic functionality running before I define
anything else in detail. I&#8217;m still weighing whether it will make sense
to have a &#8216;raw&#8217; representation of sequences and alignment blocks
rather than just using (and presumably subclassing) the
<a href="https://github.com/pjotrp/bioruby-alignment">bio-alignment</a>
representations.</p>

<p>Once basic MAF parsing works, my next area to focus on will be indexed
access. Many use cases for MAF involve pulling a few alignments out of
very large data files, rather than batch-processing the whole
file. I&#8217;ll be focusing on the indexed-access API at first, and
building a simple interim indexing scheme similar to that used by
Biopython, probably using SQLite in a similar way. In developing the
API, I&#8217;ll study those provided by bx-python and Biopython, the two
other MAF implementations providing persistent indexing.</p>

<p>Ultimately, I plan to revisit my actual indexing method, and
potentially implement support for bx-python&#8217;s
<a href="https://bitbucket.org/james_taylor/bx-python/src/07aca5a9f6fc/lib/bx/interval_index_file.py">interval index files</a>. I&#8217;ll
also take a careful look at other database alternatives such as
Berkeley DB and Tokyo Cabinet.</p>

<p>P.S. For my next blog post, I think I will try using Markdown&#8217;s
<a href="http://daringfireball.net/projects/markdown/syntax#link">reference-style links</a>,
since the raw source for these posts is getting unwieldy with inline
links.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GSoC Week 2]]></title>
    <link href="http://csw.github.com/bioruby-maf/blog/2012/05/21/week_2_progress/"/>
    <updated>2012-05-21T11:13:00-04:00</updated>
    <id>http://csw.github.com/bioruby-maf/blog/2012/05/21/week_2_progress</id>
    <content type="html"><![CDATA[<p>This was my second week of work on my GSoC project, and the last week
of the &#8216;community bonding&#8217; period before the official start of
coding. A major focus of mine was BioRuby&#8217;s
<a href="http://phyloxml.org/">phyloXML</a> support; it uses libxml, which has
been causing unit test failures under JRuby. In the end, the best
course of action seemed to separate the phyloXML support as a separate
plugin, which I have done as the
<a href="https://github.com/csw/bioruby-phyloxml">bio-phyloxml</a> gem. This will
remove BioRuby&#8217;s dependency on XML libraries entirely and that JRuby
issue along with it. At the same time, users of the phyloXML code
should be able to continue using it with no substantive changes.</p>

<p>Separately, I began porting this phyloXML code to use
<a href="http://nokogiri.org/">Nokogiri</a> instead of libxml-ruby, but ran into
difficulties with this effort. While it is possible, and the library
APIs are very similar, the code uses relatively low-level XML
processing APIs in ways that seem to be sensitive to subtle
differences in text node and namespace semantics between the two
libraries. Substantial restructuring of the code and the addition of
quite a few unit tests might be necessary to carry out such a port
with confidence that the resulting code would work well.</p>

<p>Also, someone else submitted a
<a href="https://github.com/jruby/jruby/pull/176">JRuby patch</a> for
<a href="http://jira.codehaus.org/browse/JRUBY-6658">JRUBY-6658</a>, one of the
major causes of BioRuby&#8217;s unit test failures with JRuby; once a fix is
integrated, we&#8217;ll be close to having all the tests passing under
JRuby.</p>

<p>I identified another JRuby bug,
<a href="http://jira.codehaus.org/browse/JRUBY-6666">JRUBY-6666</a>, causing
several unit test failures. This one affects BioRuby&#8217;s code for
running external commands, so it would be likely to be encountered in
production use. For this one, I also worked up a
<a href="https://github.com/jruby/jruby/pull/173">patch</a>.</p>

<p>I also spent some time preparing a performance testing environment,
for evaluating existing MAF implementations as well as my own. This
will be important, since I will be considering the use of an existing
C parser. I will also want to ensure that the performance of my code
is competitive with the alternatives. Lacking any hardware more
powerful than a MacBook Air, I am setting this up with Amazon EC2. To
simplify environment setup, I&#8217;ll be using
<a href="http://wiki.opscode.com/display/chef/Home">Chef</a>. I&#8217;ve already set up
a <a href="https://github.com/csw/chef-repo">Chef repository</a> with
configuration logic, and some
<a href="https://github.com/csw/ec2-launcher">rudimentary code</a> to streamline
launching Ubuntu machines on EC2 and bootstrapping a Chef
environment. To save money, I plan to make use of
<a href="http://aws.amazon.com/ec2/spot-instances/">EC2 Spot Instances</a>, which
are perfect for instances that only need to run for a few hours for
batch tasks.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GSoC Week 1]]></title>
    <link href="http://csw.github.com/bioruby-maf/blog/2012/05/13/progress/"/>
    <updated>2012-05-13T18:14:00-04:00</updated>
    <id>http://csw.github.com/bioruby-maf/blog/2012/05/13/progress</id>
    <content type="html"><![CDATA[<p>This has been my first half-week of work on my Google Summer of Code
project, and it&#8217;s off to an exciting start. The first order of
business has been to get my development environment together; since
I&#8217;ve been a microbiology student instead of a programmer for the last
year, it&#8217;s taken some work. In that process, I&#8217;ve ended up making a
few <a href="https://github.com/michaelklishin/cucumber.el/pull/21">open</a>
<a href="https://github.com/nibrahim/Hyde/pull/6">source</a>
<a href="https://github.com/nibrahim/Hyde/pull/7">contributions</a> just to get
my tools working the way I want. I&#8217;m running GNU Emacs 24 and trying
to take more advantage of it than I have in the past. I&#8217;ll have much
more to say about this in a future post.</p>

<p>I&#8217;ve also started working on the BioRuby unit test
<a href="http://travis-ci.org/#!/bioruby/bioruby/jobs/1296529">failures</a> under
JRuby, as a way of familiarizing myself with the BioRuby code base as
well as the community and its development processes. Right now, JRuby
in 1.8 mode is showing 6 failures and 126 errors, which is hardly
confidence-inspiring for people considering using JRuby with
BioRuby. This is too bad, since JRuby has some definite advantages as
a Ruby implementation. After looking into these failures, I&#8217;ve broken them
down into a few categories:</p>

<ul>
<li>temporary file permissions problems, likely due to some sort of Travis-CI
environment issue</li>
<li>a bug in JRuby&#8217;s implementation of
<a href="http://ruby-doc.org/stdlib-1.8.7/libdoc/open3/rdoc/Open3.html#method-c-popen3">Open3.popen3</a>
which I&#8217;m working up a bug report for</li>
<li>an odd autoload problem I&#8217;ve filed
<a href="https://jira.codehaus.org/browse/JRUBY-6658">JRUBY-6658</a> for and
sent an accompanying
<a href="https://github.com/rubyspec/rubyspec/pull/136">RubySpec patch</a>
for</li>
<li>a problem with libxml-jruby, which appears unmaintained, for which
I&#8217;ve submitted a
<a href="https://github.com/bioruby/bioruby/pull/55">BioRuby patch</a> plus
<a href="http://jira.codehaus.org/browse/JRUBY-6662">JRUBY-6662</a></li>
<li>and a small test case bug relating to floating point handling,
which I&#8217;ve submitted a
<a href="https://github.com/bioruby/bioruby/pull/54">patch</a> for.</li>
</ul>


<p>Once these are resolved, JRuby should be passing the BioRuby unit
tests in 1.8 mode, and closer to passing in 1.9 mode. (There are a few
extra failures under 1.9 that I haven&#8217;t sorted through yet.)</p>

<p>I&#8217;ve also gotten a start on my project itself, creating the
<a href="https://github.com/csw/bioruby-maf">bioruby-maf</a> Github repository
with a project skeleton and writing my
<a href="https://github.com/csw/bioruby-maf/blob/79004f9b75c1e33f9b265a1a97241d3c9d382997/features/maf-to-fasta.feature">first Cucumber feature</a>
for it. This is, in fact, my first Cucumber feature ever. However, I
did spend a few cross-country flights reading the
<a href="http://pragprog.com/book/achbd/the-rspec-book">RSpec</a> and
<a href="http://pragprog.com/book/hwcuc/the-cucumber-book">Cucumber</a> books
last week; between that and cribbing from
<a href="https://github.com/pjotrp/bioruby-alignment/tree/master/features">Pjotr&#8217;s code</a>
I feel like I have some idea what I&#8217;m doing. Just assembling that
feature has been useful, too, since I&#8217;ve had to get several of the
existing MAF tools running on my machine. In fact, my test MAF data and
the FASTA version of it are courtesy of
<a href="https://bitbucket.org/james_taylor/bx-python/wiki/Home">bx-python</a>,
which will be my reference implementation in many respects.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hello World]]></title>
    <link href="http://csw.github.com/bioruby-maf/blog/2012/05/09/hello-world/"/>
    <updated>2012-05-09T19:33:00-04:00</updated>
    <id>http://csw.github.com/bioruby-maf/blog/2012/05/09/hello-world</id>
    <content type="html"><![CDATA[<p>Hello World! This blog will be tracking the development of <a href="https://github.com/csw/bioruby-maf">bio-maf</a>, a <a href="https://cgwb.nci.nih.gov/FAQ/FAQformat.html#format5">Multiple Alignment Format</a> (MAF) parser for the Ruby bioinformatics library <a href="http://bioruby.open-bio.org/">BioRuby</a>, as part of the Google Summer of Code 2012. I&#8217;m Clayton Wheeler, a programmer and a biology student at the University of Michigan. This is exciting for me as my first substantial open source project, and as a way to write hopefully-useful bioinformatics software. And thanks, Google, for making this possible.</p>

<p>In my next post I&#8217;ll discuss what MAF is, what it&#8217;s useful for, and how I&#8217;m planning to approach the project. I&#8217;ll be making weekly status posts, plus others as inspiration strikes.</p>
]]></content>
  </entry>
  
</feed>
